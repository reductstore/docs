---
title: Computer Vision Made Simple with ReductStore and Roboflow
description: Learn how to use ReductStore and Roboflow to easily build and deploy computer vision models for real-time applications on edge devices.
authors: anthony
tags: [computer vision, edge computing, roboflow]
slug: robotflow-reductstore
date: 2024-09-24
img: ./img/reductstore_robotflow.drawio.png
---

![Roboflow and ReductStore](./img/reductstore_robotflow.drawio.png)

Computer vision is transforming industries by automating decision making based on visual data.
From facial recognition to autonomous driving, the need for efficient computer vision solutions is growing rapidly. 
This article explores how Roboflow combined with ReductStore, a time-series object store optimized for managing continuous data streams, can improve computer vision applications. ReductStore is designed to efficiently handle high-frequency time-series data, such as video streams, making it a perfect fit for storing and retrieving large datasets generated by computer vision tasks.

In this article, we will cover:
- [**Challenges of Traditional Computer Vision Model Deployment**](#challenges-of-traditional-computer-vision-model-deployment)
- [**What is Roboflow?**](#what-is-roboflow)
- [**Benefits of Using Roboflow Inference**](#benefits-of-using-roboflow-inference)
- [**Choosing the Right Computer Vision Model**](#choosing-the-right-computer-vision-model)
- [**Deployment Methods**](#deployment-methods)
- [**Cloud vs. Edge Deployment**](#cloud-vs-edge-deployment)
- [**ReductStore for Efficient Data Management**](#reductstore-for-efficient-data-management)

By the end of this article, you will have a clear understanding of how to leverage Roboflow and ReductStore to build and deploy computer vision models for real-time applications on edge devices. You can find the complete code example for this article on GitHub under the [**reductstore/reduct-roboflow-example**](https://github.com/reductstore/reduct-roboflow-example) repository.

{/* truncate */}

Challenges of Traditional Computer Vision Model Deployment
----------------------------------------------------------

There are several challenges to deploying computer vision models that can hinder the efficiency and scalability of projects. 
Some of the key issues include

1.  Complex infrastructure requirements: Traditional computer vision models often require a powerful computing infrastructure. This includes high-end GPUs, specialized hardware, and optimized software configurations. For many organizations, setting up this infrastructure can be time consuming and costly.
    
2.  High computational cost and latency: Running models, especially for real-time applications, requires significant computing power. As a result, inference on high-resolution images or video streams can result in high latency, which is problematic for time-sensitive applications such as autonomous vehicles or real-time surveillance.
    
3.  Difficulty managing large datasets: Computer vision models often require large amounts of labeled data for training. Managing these datasets, especially in real-time environments or over extended periods of time, creates additional hurdles for data storage, retrieval, and processing.
    

What is Roboflow?
-----------------

Roboflow is a comprehensive platform designed to simplify the process of building, training, and deploying state-of-the-art computer vision models. 
It provides tools that help developers and data scientists streamline the entire workflow, from dataset creation to model inference.

![Roboflow Dashboard](./img/roboflow_dashboard.png)

Some of Roboflow's key features include

1.  Dataset management: Roboflow allows users to easily upload, organize, and pre-process large datasets. It supports multiple image formats and automatically labels, resizes, and augments data to improve model accuracy.
    
2.  Model Training and Optimization: With Roboflow, users can choose from a wide range of pre-trained models or train their own from scratch. The platform provides tools to optimize models for different hardware environments, whether in the cloud or at the edge.
    
3.  Model Deployment: Roboflow makes it easy to deploy models in different environments, such as on-device, edge or cloud-based systems. Its intuitive interface allows users to integrate computer vision models into applications without extensive coding or setup.
    

By providing these services in an easy-to-use manner, Roboflow lowers the barrier to entry for computer vision projects and makes the technology accessible to a broader audience.

Benefits of Using Roboflow Inference
------------------------------------

Roboflow Inference provides a robust and efficient way to deploy computer vision models. 
It is designed to simplify the deployment process while maintaining flexibility and performance. 
Below are some of the key benefits of using Roboflow Inference:

### Cost-effectiveness

Roboflow Inference eliminates the need for expensive infrastructure by providing optimized, scalable deployment solutions. It allows developers to efficiently run models on low-cost hardware or in the cloud, minimizing the cost of scaling and maintaining custom environments.

### Minimal setup requirements

One of the outstanding features of Roboflow Inference is its ease of setup. The platform supports a wide range of devices, from powerful cloud GPUs to lightweight edge devices, without requiring significant hardware investments. This enables rapid deployment without complex configuration.

### Offline capabilities

For edge computing applications where Internet connectivity is limited or unreliable, Roboflow Inference supports offline deployments. This feature is especially valuable in areas such as autonomous vehicles, industrial IoT, or remote monitoring, where reliable, low-latency processing is critical.

Choosing the Right Computer Vision Model
----------------------------------------

Selecting the right model for your computer vision application is critical to achieving the best performance. Roboflow simplifies this process by offering a wide range of models, each suitable for different tasks and environments.

### Understanding the Roboflow Universe

Roboflow provides access to an extensive library of pre-trained models, commonly referred to as the Roboflow Universe. 
This library covers various tasks such as object detection, image classification, and segmentation. 
Users can either use these foundation models directly or fine-tune them based on their specific dataset, significantly reducing the time required for model development.

![Roboflow Universe](./img/roboflow_universe.png)

### Criteria for model selection

When choosing a model, consider the following factors

1.  Task type: Determine whether your project involves object detection, image classification, or image segmentation.
    
2.  Model Accuracy: Select a model that meets the accuracy requirements of your application. Pre-trained models such as YOLO, MobileNet, or EfficientDet are available for high performance tasks.
    
3.  Hardware limitations: Make sure the model you select fits your hardware. For example, smaller models like MobileNet are ideal for edge devices, while more complex models like YOLOv5 can be used in cloud deployments for higher accuracy.
    
4.  Latency requirements: For real-time applications such as video surveillance or autonomous systems, choose models that provide low latency during inference.

Roboflow's model library is organized to make it easy to browse and select the most appropriate model based on these criteria.

![Roboflow Model Selection](./img/roboflow_model_selection.png)

### Roboflow Workflows to Divide and Conquer

Especially in computer vision, breaking down complex tasks into smaller steps can significantly improves accuracy and efficiency.

For instance, recognizing digits on license plates can be split into two tasks: one model detects and localizes the plates, while another focuses on digit recognition. This pipeline approach allows each model to specialize, resulting in better performance. In contrast, using a single model to handle both tasks simultaneously introduces challenges, such as dealing with varied lighting, camera angles, and different plate designs, leading to reduced accuracy and a more complex development process.

![Roboflow Workflows](./img/roboflow_workflows.png)

Benefits of the pipeline approach include:

*   Improved accuracy as each model handles fewer variables.
    
*   Faster development by working on models in parallel.
    
*   Easier debugging with isolated components.
    
*   Scalability since individual models can be updated independently.
    
*   Reusability of the workflow for other tasks or projects.

With split workflow                                              | Without split workflow
-----------------------------------------------------------------|-----------------------------------------------------------------------
![Result with split workflow](./img/roboflow_split_workflow.png) | ![Result without split workflow](./img/roboflow_no_split_workflow.png)


Deployment Methods
------------------

Roboflow Inference offers several deployment methods, making it flexible for different types of applications. 
Whether you're working with single image analysis, real-time video streams, or offline scenarios, Roboflow can handle these use cases efficiently.

### Deploying on a Single Image

[https://docs.roboflow.com/deploy/self-hosted-deployments/what-is-inference](https://docs.roboflow.com/deploy/self-hosted-deployments/what-is-inference)

For basic applications such as object recognition or classification of a single image, Roboflow allows you to upload an image and instantly perform inference using a selected model. The process includes

1.  Loading the image.
    
2.  Applying the pre-trained model for detection or classification.
    
3.  Obtain real-time results, including labels and bounding boxes for detected objects.

```python
import cv2
from inference_sdk import InferenceHTTPClient
import supervision as sv

# Load the example image
image = cv2.imread("img/image_example.png")

# Perform inference using Roboflow Inference
CLIENT = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",
    api_key="0V9NRqITldFn0MFxy9jb",  # Public API key for demonstration purposes
)
predictions = CLIENT.infer(image, model_id="hard-hat-sample-hicg4/3")

# Annotate the image with the detected objects
labels = [item["class"] for item in predictions["predictions"]]
detections = sv.Detections.from_inference(predictions)

label_annotator = sv.LabelAnnotator()
box_annotator = sv.BoxAnnotator()

annotated_image = box_annotator.annotate(scene=image.copy(), detections=detections)
annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)
```

Image Example | Image Annotated
-------------|-----------------
![Image Example](./img/image_example.png) | ![Image Annotated](./img/image_annotated.png)

This method is fast, straightforward, and ideal for tasks where high-speed processing isn't critical.

### Streaming Video Deployment

For real-time applications, Roboflow supports the deployment of models on video streams. This is particularly useful for use cases such as surveillance, traffic monitoring, and live event detection. Roboflow processes each video frame through the model, ensuring real-time analysis. Steps involved:

1.  Connect your video stream (e.g. from a camera feed).
    
2.  Apply the selected model to each frame in real time.
    
3.  Output object detections or classifications frame-by-frame.

[https://docs.roboflow.com/workflows/deploy-a-workflow](https://docs.roboflow.com/workflows/deploy-a-workflow)

```python
from inference import InferencePipeline

# Define a custom sink function to process the model predictions
def my_sink(result, video_frame):
    ...
    
# Initialize the InferencePipeline with the desired workflow
pipeline = InferencePipeline.init_with_workflow(
    api_key="API_KEY",
    workspace_name="workspace-name",
    workflow_id="workflow-id",
    video_reference=0,
    on_prediction=my_sink
)
pipeline.start()
pipeline.join()
```
    

Cloud vs. Edge Deployment
-------------------------

The choice between cloud and edge depends on the nature of your application. Each has distinct advantages that may influence your decision.

### Advantages of Cloud Deployment

*   Scalability: Cloud-based deployments can handle large-scale processing, making them ideal for applications that require heavy computation.
    
*   Ease of access: You can deploy and access models from anywhere, and roll out updates easily.
    

### Advantages of Edge Deployment

*   Reduced latency: Running models on edge devices minimizes latency, which is critical for real-time applications.
    
*   Offline operation: Edge deployments allow models to run in environments where Internet connectivity is unavailable or intermittent.
    

ReductStore for Efficient Data Management
-----------------------------------------

ReductStore plays a critical role in managing the massive amounts of data generated by computer vision models, especially in real-time applications. 
It is a time-series object store designed for continuous data streams, making it highly efficient for storing and managing image data along with AI-generated labels.

![ReductStore for Efficient Data Management](./img/reductstore_pipeline.drawio.png)

### ReductStore Setup

Create a `docker-compose.yml` file with the following content:

```yaml
version: "3.8"

services:
  reductstore:
    image: reduct/store:latest
    ports:
      - "8383:8383"
    volumes:
      - data:/data
    environment:
      - RS_API_TOKEN=my-token

volumes:
  data:
    driver: local
```

Then we ca run ReductStore with:

```bash
docker compose up -d
```

This will start ReductStore on port 8383 with a simple API token for authentication.

![ReductStore Web Console](./img/reductstore_web_console.png)

### Python Setup

Make sure you have Python 3.8+ installed in your environment.
Then simply install the necessary libraries for our example using pip:

### Storing Images with AI Labels at the Edge

[https://www.reduct.store/docs/next/guides/data-ingestion](https://www.reduct.store/docs/next/guides/data-ingestion)

One of the key challenges in edge computing is managing large data sets generated by cameras or other imaging devices. ReductStore addresses this by

1.  Storing high-frequency image data: Efficiently manages the storage of continuous streams of images captured at the edge.
    
2.  AI-generated labels: ReductStore supports the storage of metadata, such as object labels, directly with the images, simplifying future analysis and retrieval of information.
    
3.  Efficient storage management: By optimizing the way images and metadata are stored, ReductStore reduces the overhead of managing large volumes of data on limited edge devices.
    
```python
import time
from reduct import Client, Bucket

async with Client("http://127.0.0.1:8383", api_token="my-token") as client:
    bucket: Bucket = await client.create_bucket("my-bucket-1", exist_ok=True)
    ts = time.time()
    await bucket.write(
        "roboflow",
        image_bytes,
        ts,
        labels=flat_predictions,
        content_type="text/plain",
    )
```

### Selective Data Replication to the Cloud

[https://www.reduct.store/docs/next/guides/data-replication](https://www.reduct.store/docs/next/guides/data-replication)

While edge storage is critical for low-latency processing, cloud storage provides scalability and backup for long-term data retention. ReductStore provides selective data replication capabilities that allow users to

1.  Replicate only critical data: Instead of sending all data to the cloud, developers can select which images and metadata to replicate, reducing cloud storage costs.
    
2.  Seamless Sync: ReductStore efficiently synchronizes the selected data with cloud-based storage systems, ensuring that critical information is preserved while maintaining real-time operations at the edge.
    
For setting up replication, you can use the ReductStore web console or the API to define rules for data replication based on specific criteria, such as image metadata, timestamps, or object labels.

![ReductStore Data Replication](./img/reductstore_data_replication.png)

Conclusion
----------

The combination of Roboflow and ReductStore provides a comprehensive solution for efficiently deploying and managing computer vision models. Roboflow simplifies the model development and deployment process, making it accessible to developers and data scientists, while ReductStore ensures that the massive amounts of data generated by these models are effectively managed, especially in real-time environments such as video streams.

Whether deployed in the cloud or at the edge, these tools reduce operational complexity, lower costs, and provide the flexibility to scale computer vision applications. As computer vision continues to evolve, leveraging these platforms and using pre-trained models from Roboflow Universe

FAQ
---

### What hardware is recommended for Inference?
NVIDIA GPUs are recommended for high-performance tasks, but models can run on CPUs for smaller workloads or edge devices.

### Can I use Roboflow for offline deployments?
Yes, Roboflow Inference supports offline deployment, which is especially useful for edge devices with limited or no Internet connectivity.

### How does ReductStore optimize data storage for computer vision tasks?
ReductStore efficiently manages high-frequency data streams, enabling storage of continuous image data and AI labels with minimal overhead.

### What are the benefits of edge deployment for computer vision models?
Edge deployment offers reduced latency, offline operation, and improved data security by processing data locally on the device.

### Is Roboflow suitable for both small and large projects?
Yes, Roboflow is highly scalable, making it suitable for everything from small projects to large-scale, enterprise-level computer vision deployments.